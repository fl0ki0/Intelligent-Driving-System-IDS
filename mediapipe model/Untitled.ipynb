{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc25bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isgoh\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pygame\n",
    "from pygame import mixer\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Initialize CSV file\n",
    "csv_filename = 'attentiveness_data.csv'\n",
    "\n",
    "def initialize_csv_file():\n",
    "    if not os.path.exists(csv_filename):\n",
    "        with open(csv_filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Time\", \"Blink Count\", \"Yawn Count\", \"Drowsiness Count\", \"Out of Frame\", \"Fatigue Status\"])\n",
    "\n",
    "def append_data_to_csv(time, blink_count, yawn_count, drowsiness_count, outof_frame, fatigue_status):\n",
    "    with open(csv_filename, 'a', newline='') as file:  \n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([time, blink_count, yawn_count, drowsiness_count, outof_frame, fatigue_status])\n",
    "        \n",
    "initialize_csv_file()\n",
    "\n",
    "# Initialize sound\n",
    "mixer.init()\n",
    "watch_out = mixer.Sound('watch_out.wav')\n",
    "eyes_blink = mixer.Sound('wake_up_alarm.mp3')\n",
    "yawn = mixer.Sound('coffe.wav')\n",
    "welcome_sound = mixer.Sound('welcome.wav')\n",
    "\n",
    "# Function to calculate eye openness\n",
    "def open_len(arr):\n",
    "    y_arr = [y for _, y in arr]\n",
    "    min_y = min(y_arr)\n",
    "    max_y = max(y_arr)\n",
    "    return max_y - min_y\n",
    "\n",
    "# Mediapipe initialization\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "RIGHT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "LEFT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]\n",
    "UPPER_LIP = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291]\n",
    "LOWER_LIP = [146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14]\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "welcome_sound.play()\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.3,\n",
    "        min_tracking_confidence=0.3\n",
    ") as face_mesh:\n",
    "\n",
    "    drowsy_frames = 0\n",
    "    max_left = 0\n",
    "    max_right = 0\n",
    "    blink_count = 0\n",
    "    eye_closed = False\n",
    "    eye_open_frames = []\n",
    "    yawn_frames = 0\n",
    "    yawn_count = 0\n",
    "    drowsiness_count = 0\n",
    "    fatigue_status = \"Normal\"\n",
    "    left_frames = 0\n",
    "    right_frames = 0\n",
    "    down_frames = 0\n",
    "    threshold_frames = 90\n",
    "    outof_frame = 0\n",
    "    screenshot_counter = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv.flip(frame, 1)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        img_h, img_w = frame.shape[:2]\n",
    "        cv.putText(frame, \"Hi I'm HIMOQ! your AI Attentive assistant.\", (50, img_h - 50), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                all_landmarks = np.array(\n",
    "                    [np.multiply([p.x, p.y], [img_w, img_h]).astype(int) for p in face_landmarks.landmark])\n",
    "\n",
    "                right_eye = all_landmarks[RIGHT_EYE]\n",
    "                left_eye = all_landmarks[LEFT_EYE]\n",
    "                upper_lip = all_landmarks[UPPER_LIP]\n",
    "                lower_lip = all_landmarks[LOWER_LIP]\n",
    "\n",
    "                cv.polylines(frame, [left_eye], True, (0, 255, 0), 1, cv.LINE_AA)\n",
    "                cv.polylines(frame, [right_eye], True, (0, 255, 0), 1, cv.LINE_AA)\n",
    "                cv.polylines(frame, [upper_lip], True, (255, 0, 0), 1, cv.LINE_AA)\n",
    "                cv.polylines(frame, [lower_lip], True, (255, 0, 0), 1, cv.LINE_AA)\n",
    "\n",
    "                len_left = open_len(right_eye)\n",
    "                len_right = open_len(left_eye)\n",
    "                mouth_openness = open_len(upper_lip) + open_len(lower_lip)\n",
    "\n",
    "                current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                cv.putText(frame, current_time, (400, 30), cv.FONT_HERSHEY_SIMPLEX, .5, (255, 255, 255), 2)\n",
    "\n",
    "                # Use a moving average for eye openness\n",
    "                eye_open_frames.append((len_left + len_right) / 2)\n",
    "                if len(eye_open_frames) > 10:  # consider more frames for a smoother average\n",
    "                    eye_open_frames.pop(0)\n",
    "                avg_eye_openness = sum(eye_open_frames) / len(eye_open_frames)\n",
    "\n",
    "                if avg_eye_openness <= (max_left + max_right) / 7:\n",
    "                    if not eye_closed:\n",
    "                        blink_count += 1\n",
    "                        eye_closed = True\n",
    "                else:\n",
    "                    eye_closed = False\n",
    "\n",
    "                if len_left > max_left:\n",
    "                    max_left = len_left\n",
    "                if len_right > max_right:\n",
    "                    max_right = len_right\n",
    "\n",
    "                # Enhanced drowsiness detection logic\n",
    "                if (len_left <= max_left / 2 and len_right <= max_right / 2):\n",
    "                    drowsy_frames += 1\n",
    "                else:\n",
    "                    drowsy_frames = 0\n",
    "\n",
    "                if (drowsy_frames > 60):  # Reduce the threshold for quicker detection\n",
    "                    drowsiness_count += 1\n",
    "                    drowsy_frames = 0\n",
    "                    eyes_blink.play()\n",
    "                    screenshot_filename = f\"drowsiness_screenshot_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}_{screenshot_counter}.jpg\"\n",
    "                    cv.imwrite(screenshot_filename, frame)\n",
    "                    screenshot_counter += 1\n",
    "\n",
    "                if mouth_openness > 50:\n",
    "                    yawn_frames += 1\n",
    "                    if yawn_frames > 40:\n",
    "                        yawn_count += 1\n",
    "                        yawn_frames = 0\n",
    "                        yawn.play()\n",
    "                else:\n",
    "                    yawn_frames = 0\n",
    "\n",
    "                if drowsiness_count < 5 and yawn_count < 5:\n",
    "                    fatigue_status = \"Normal\"\n",
    "                elif 5 <= drowsiness_count <= 10 or 5 <= yawn_count <= 10:\n",
    "                    fatigue_status = \"Tired\"\n",
    "                else:\n",
    "                    fatigue_status = \"Very Tired\"\n",
    "\n",
    "                face_2d = []\n",
    "                face_3d = []\n",
    "                for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                    if idx in [33, 263, 1, 61, 291, 199]:\n",
    "                        x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "                        face_2d.append([x, y])\n",
    "                        if idx == 1:\n",
    "                            nose_2d = (x, y)\n",
    "                            nose_3d = (x, y, lm.z * 3000)\n",
    "                        face_3d.append([x, y, lm.z])\n",
    "\n",
    "                face_2d = np.array(face_2d, dtype=np.float64)\n",
    "                face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "                focal_length = 1 * img_w\n",
    "                cam_matrix = np.array([[focal_length, 0, img_h / 2],\n",
    "                                       [0, focal_length, img_w / 2],\n",
    "                                       [0, 0, 1]])\n",
    "                distortion_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "                success, rotation_vec, translation_vec = cv.solvePnP(face_3d, face_2d, cam_matrix, distortion_matrix)\n",
    "                rmat, jac = cv.Rodrigues(rotation_vec)\n",
    "                angles, mtxR, mtxQ, Qx, Qy, Qz = cv.RQDecomp3x3(rmat)\n",
    "\n",
    "                x = angles[0] * 360\n",
    "                y = angles[1] * 360\n",
    "                z = angles[2] * 360\n",
    "\n",
    "                if y >= -10:\n",
    "                    left_frames = 0\n",
    "                if y <= 10:\n",
    "                    right_frames = 0\n",
    "                if x >= -10:\n",
    "                    down_frames = 0\n",
    "\n",
    "                if y < -10:\n",
    "                    left_frames += 1\n",
    "                    text = \"Looking Left!!!\"\n",
    "                    if left_frames > threshold_frames:\n",
    "                        watch_out.play()\n",
    "                        left_frames = 0\n",
    "                        outof_frame += 1\n",
    "                elif y > 10:\n",
    "                    right_frames += 1\n",
    "                    text = \"Looking Right!!!\"\n",
    "                    if right_frames > threshold_frames:\n",
    "                        watch_out.play()\n",
    "                        right_frames = 0\n",
    "                        outof_frame += 1\n",
    "                elif x < -10:\n",
    "                    down_frames += 1\n",
    "                    text = \"Looking Down!!!\"\n",
    "                    if down_frames > threshold_frames:\n",
    "                        watch_out.play()\n",
    "                        down_frames = 0\n",
    "                        outof_frame += 1\n",
    "                else:\n",
    "                    text = \"Forward!!!\"\n",
    "\n",
    "                cv.putText(frame, text, (40, 300), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv.putText(frame, f'Blinks: {blink_count}', (50, 50), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv.putText(frame, f'Yawns: {yawn_count}', (50, 100), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv.putText(frame, f'Drowsiness: {drowsiness_count}', (50, 150), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv.putText(frame, f'Fatigue: {fatigue_status}', (50, 200), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv.putText(frame, f'Out of frame: {outof_frame}', (50, 250), cv.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        cv.imshow('img', frame)\n",
    "        current_time = datetime.datetime.now()\n",
    "        if (current_time - start_time).total_seconds() >= 20:\n",
    "            append_data_to_csv(current_time.strftime(\"%Y-%m-%d %H:%M:%S\"), blink_count, yawn_count, drowsiness_count, outof_frame, fatigue_status)\n",
    "            start_time = current_time  # Reset start time\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b25c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating insights for 2024-07-19:\n",
      "daily_summary: On 2024-07-19, you blinked 66 times, yawned 5 times, had 12 drowsiness incidents, and were out of frame 13 times.\n",
      "trend_insight: Your blinking rate is higher than yawn count, indicating general alertness.\n",
      "recommendation: Consider taking more frequent breaks or adjusting your driving schedule to avoid drowsiness.\n",
      "fatigue_status_overview: Your fatigue status is normal. Continue driving safely.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 102\u001b[0m\n\u001b[0;32m     97\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     99\u001b[0m df \u001b[38;5;241m=\u001b[39m convert_to_dataframe(aggregated_data)\n\u001b[1;32m--> 102\u001b[0m model \u001b[38;5;241m=\u001b[39m train_predictive_model(df)\n\u001b[0;32m    103\u001b[0m anomalies \u001b[38;5;241m=\u001b[39m detect_anomalies(df)\n\u001b[0;32m    105\u001b[0m visualize_data(df)\n",
      "Cell \u001b[1;32mIn[2], line 73\u001b[0m, in \u001b[0;36mtrain_predictive_model\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     71\u001b[0m X \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblink_count\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myawn_count\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     72\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrowsiness_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 73\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     74\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     75\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2661\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2662\u001b[0m )\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "def read_and_aggregate_data(csv_filename):\n",
    "    aggregated_data = defaultdict(lambda: {'blink_count': 0, 'yawn_count': 0, 'drowsiness_count': 0, 'out_of_frame': 0, 'fatigue_status_counts': defaultdict(int)})\n",
    "    \n",
    "    with open(csv_filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            date = datetime.strptime(row['Time'].split(' ')[0], '%Y-%m-%d').date()\n",
    "            aggregated_data[date]['blink_count'] += int(row['Blink Count'])\n",
    "            aggregated_data[date]['yawn_count'] += int(row['Yawn Count'])\n",
    "            aggregated_data[date]['drowsiness_count'] += int(row['Drowsiness Count'])\n",
    "            aggregated_data[date]['out_of_frame'] += int(row['Out of Frame'])\n",
    "            aggregated_data[date]['fatigue_status_counts'][row['Fatigue Status']] += 1\n",
    "    \n",
    "    for date, data in aggregated_data.items():\n",
    "        data['fatigue_status'] = max(data['fatigue_status_counts'], key=data['fatigue_status_counts'].get)\n",
    "        del data['fatigue_status_counts']  \n",
    "    \n",
    "    return aggregated_data\n",
    "\n",
    "def generate_attentiveness_insights(date, data):\n",
    "    print(f\"Generating insights for {date}:\")\n",
    "    print(f\"daily_summary: On {date}, you blinked {data['blink_count']} times, yawned {data['yawn_count']} times, had {data['drowsiness_count']} drowsiness incidents, and were out of frame {data['out_of_frame']} times.\")\n",
    "    if data['yawn_count'] > data['blink_count']:\n",
    "        print(\"trend_insight: You tend to yawn more frequently than blink, which might indicate tiredness.\")\n",
    "    else:\n",
    "        print(\"trend_insight: Your blinking rate is higher than yawn count, indicating general alertness.\")\n",
    "    if data['drowsiness_count'] > 5:\n",
    "        print(\"recommendation: Consider taking more frequent breaks or adjusting your driving schedule to avoid drowsiness.\")\n",
    "    else:\n",
    "        print(\"recommendation: Keep up the good work! Your attentiveness levels are commendable.\")\n",
    "    if data['fatigue_status'] == \"Very Tired\":\n",
    "        print(\"fatigue_status_overview: You were very tired on this day. Ensure you get some rest before your next drive.\")\n",
    "    elif data['fatigue_status'] == \"Tired\":\n",
    "        print(\"fatigue_status_overview: You showed signs of tiredness. Stay hydrated and take short breaks.\")\n",
    "    else:\n",
    "        print(\"fatigue_status_overview: Your fatigue status is normal. Continue driving safely.\")\n",
    "    print(\"\\n\")  \n",
    "\n",
    "csv_filename = 'attentiveness_data.csv'\n",
    "aggregated_data = read_and_aggregate_data(csv_filename)\n",
    "\n",
    "for date in sorted(aggregated_data.keys()):\n",
    "    generate_attentiveness_insights(date, aggregated_data[date])\n",
    "\n",
    "def convert_to_dataframe(aggregated_data):\n",
    "    df = pd.DataFrame.from_dict(aggregated_data, orient='index')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df['day_of_week'] = df.index.day_name()\n",
    "    df['month'] = df.index.month\n",
    "    return df\n",
    "\n",
    "def perform_correlation_analysis(df):\n",
    "    correlation_matrix = df[['blink_count', 'yawn_count', 'drowsiness_count']].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True)\n",
    "    plt.show()\n",
    "\n",
    "def train_predictive_model(df):\n",
    "    X = df[['blink_count', 'yawn_count']]\n",
    "    y = df['drowsiness_count']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    clf = IsolationForest(random_state=42)\n",
    "    df['anomaly'] = clf.fit_predict(df[['drowsiness_count']])\n",
    "    anomalies = df[df['anomaly'] == -1]\n",
    "    return anomalies\n",
    "\n",
    "def visualize_data(df):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(df.index, df['blink_count'], color='blue', label='Blink Count')\n",
    "    plt.scatter(df.index, df['yawn_count'], color='red', label='Yawn Count')\n",
    "    plt.scatter(df.index, df['drowsiness_count'], color='green', label='Drowsiness Count')\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Driver Behavior Metrics Over Time')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "df = convert_to_dataframe(aggregated_data)\n",
    "\n",
    "\n",
    "model = train_predictive_model(df)\n",
    "anomalies = detect_anomalies(df)\n",
    "\n",
    "visualize_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce59b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
